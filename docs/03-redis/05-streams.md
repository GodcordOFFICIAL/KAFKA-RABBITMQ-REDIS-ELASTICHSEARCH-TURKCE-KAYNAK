# Redis Streams - Event Streaming ile Redis

## ğŸ“‹ Ã–zet

Redis Streams, Redis 5.0 ile tanÄ±tÄ±lan ve event streaming, message queues ve time-series data iÃ§in optimize edilmiÅŸ gÃ¼Ã§lÃ¼ bir veri yapÄ±sÄ±dÄ±r. Kafka benzeri event streaming Ã¶zelliklerini Redis'in basitliÄŸi ve hÄ±zÄ± ile birleÅŸtirir.

## ğŸ¯ Learning Objectives

Bu bÃ¶lÃ¼mÃ¼ tamamladÄ±ÄŸÄ±nda:

- âœ… Redis Streams veri yapÄ±sÄ±nÄ± anlayacaksÄ±n
- âœ… Event sourcing pattern'ini uygulayabileceksin
- âœ… Consumer groups ile distributed processing yapabileceksin
- âœ… Time-series data processing geliÅŸtirebileceksin
- âœ… Stream-based microservices mimarisi kurabileceÄŸiniz
- âœ… Real-time analytics sistemleri geliÅŸtirebileceksin

## ğŸ“‹ Prerequisites

- Redis temelleri bilgisi
- Event-driven architecture kavramlarÄ±
- Message queue sistemleri anlayÄ±ÅŸÄ±
- Python/Node.js streaming concepts

## ğŸŒŠ Redis Streams Temelleri

### Stream Veri YapÄ±sÄ±

Redis Stream, time-ordered sequence of entries ÅŸeklinde organize edilmiÅŸ bir data structure'dÄ±r:

```
Stream: user_events
â”œâ”€â”€ 1634567890123-0: {user_id: "123", action: "login", timestamp: "2021-10-18T10:11:30Z"}
â”œâ”€â”€ 1634567891456-0: {user_id: "456", action: "purchase", product: "laptop", amount: 999}
â”œâ”€â”€ 1634567892789-0: {user_id: "123", action: "logout", duration: 3600}
â””â”€â”€ 1634567893012-0: {user_id: "789", action: "signup", email: "user@domain.com"}
```

### Stream ID Format

```
<timestamp_ms>-<sequence_number>
1634567890123-0
     â†‘        â†‘
timestamp   sequence
(ms)        number
```

### Temel Stream KomutlarÄ±

```bash
# Entry ekleme
XADD stream_name * field1 value1 field2 value2

# Stream okuma (range)
XRANGE stream_name - + COUNT 10

# Real-time okuma
XREAD COUNT 10 STREAMS stream_name $

# Consumer group oluÅŸturma
XGROUP CREATE stream_name group_name $ MKSTREAM

# Consumer group ile okuma
XREADGROUP GROUP group_name consumer_name COUNT 10 STREAMS stream_name >
```

## ğŸ’» Python ile Redis Streams

### Stream Producer

```python
import redis
import json
import time
import random
from datetime import datetime
from typing import Dict, List, Any
import uuid

class RedisStreamProducer:
    """
    Redis Streams iÃ§in event producer
    """

    def __init__(self, host='localhost', port=6379, db=0, password=None):
        """
        Stream producer baÅŸlat

        Args:
            host: Redis host
            port: Redis port
            db: Database numarasÄ±
            password: Redis password
        """
        self.redis_client = redis.Redis(
            host=host,
            port=port,
            db=db,
            password=password,
            decode_responses=True
        )

        try:
            self.redis_client.ping()
            print(f"âœ… Redis Stream Producer baÅŸlatÄ±ldÄ±: {host}:{port}")
        except redis.ConnectionError:
            print(f"âŒ Redis baÄŸlantÄ± hatasÄ±: {host}:{port}")
            raise

    def publish_event(self, stream_name: str, event_data: Dict[str, Any],
                     event_id: str = '*') -> str:
        """
        Stream'e event yayÄ±nla

        Args:
            stream_name: Stream adÄ±
            event_data: Event verisi
            event_id: Event ID (* = auto-generate)

        Returns:
            Generated event ID
        """
        try:
            # Event metadata ekle
            enriched_event = {
                **event_data,
                'published_at': datetime.now().isoformat(),
                'producer_id': 'stream_producer_v1'
            }

            # JSON field'larÄ± serialize et
            serialized_event = {}
            for key, value in enriched_event.items():
                if isinstance(value, (dict, list)):
                    serialized_event[key] = json.dumps(value)
                else:
                    serialized_event[key] = str(value)

            # Stream'e ekle
            event_id = self.redis_client.xadd(stream_name, serialized_event, id=event_id)

            print(f"ğŸ“¡ Event published to {stream_name}: {event_id}")
            return event_id

        except Exception as e:
            print(f"âŒ Event publish hatasÄ±: {e}")
            return None

    def publish_user_event(self, user_id: str, action: str, **kwargs):
        """
        User event yayÄ±nla

        Args:
            user_id: KullanÄ±cÄ± ID
            action: Action type
            **kwargs: Ek event verileri
        """
        event_data = {
            'event_type': 'user_action',
            'user_id': user_id,
            'action': action,
            'session_id': str(uuid.uuid4()),
            **kwargs
        }

        return self.publish_event('user_events', event_data)

    def publish_order_event(self, order_id: str, status: str, **kwargs):
        """
        Order event yayÄ±nla

        Args:
            order_id: SipariÅŸ ID
            status: SipariÅŸ durumu
            **kwargs: Ek order verileri
        """
        event_data = {
            'event_type': 'order_update',
            'order_id': order_id,
            'status': status,
            'updated_at': datetime.now().isoformat(),
            **kwargs
        }

        return self.publish_event('order_events', event_data)

    def publish_system_metric(self, metric_name: str, value: float, **tags):
        """
        System metric yayÄ±nla

        Args:
            metric_name: Metric adÄ±
            value: Metric deÄŸeri
            **tags: Metric tag'leri
        """
        event_data = {
            'event_type': 'system_metric',
            'metric_name': metric_name,
            'value': value,
            'timestamp': int(time.time() * 1000),  # milliseconds
            'tags': tags
        }

        return self.publish_event('system_metrics', event_data)

    def simulate_user_activity(self, duration_seconds=60):
        """
        KullanÄ±cÄ± aktivitesi simÃ¼lasyonu

        Args:
            duration_seconds: SimÃ¼lasyon sÃ¼resi
        """
        print(f"ğŸ­ User activity simÃ¼lasyonu baÅŸlÄ±yor ({duration_seconds}s)...")

        users = ['user_001', 'user_002', 'user_003', 'user_004', 'user_005']
        actions = [
            ('login', {}),
            ('page_view', {'page': '/home', 'referrer': 'google'}),
            ('page_view', {'page': '/products', 'category': 'electronics'}),
            ('add_to_cart', {'product_id': 'prod_123', 'quantity': 1}),
            ('purchase', {'order_id': 'ord_456', 'amount': 99.99}),
            ('logout', {'session_duration': random.randint(300, 3600)})
        ]

        start_time = time.time()
        event_count = 0

        try:
            while time.time() - start_time < duration_seconds:
                # Random user ve action seÃ§
                user_id = random.choice(users)
                action, extra_data = random.choice(actions)

                # Event yayÄ±nla
                self.publish_user_event(user_id, action, **extra_data)
                event_count += 1

                # Random interval
                time.sleep(random.uniform(0.1, 2.0))

            print(f"âœ… SimÃ¼lasyon tamamlandÄ±: {event_count} event yayÄ±nlandÄ±")

        except KeyboardInterrupt:
            print(f"\nğŸ›‘ SimÃ¼lasyon durduruldu: {event_count} event yayÄ±nlandÄ±")

class RedisStreamConsumer:
    """
    Redis Streams iÃ§in event consumer
    """

    def __init__(self, host='localhost', port=6379, db=0, password=None):
        """
        Stream consumer baÅŸlat
        """
        self.redis_client = redis.Redis(
            host=host,
            port=port,
            db=db,
            password=password,
            decode_responses=True
        )

        self.consumer_id = f"consumer_{uuid.uuid4().hex[:8]}"
        print(f"âœ… Redis Stream Consumer baÅŸlatÄ±ldÄ±: {self.consumer_id}")

    def create_consumer_group(self, stream_name: str, group_name: str,
                            start_id: str = '$'):
        """
        Consumer group oluÅŸtur

        Args:
            stream_name: Stream adÄ±
            group_name: Group adÄ±
            start_id: BaÅŸlangÄ±Ã§ position ($=latest, 0=beginning)
        """
        try:
            self.redis_client.xgroup_create(
                stream_name,
                group_name,
                id=start_id,
                mkstream=True
            )
            print(f"âœ… Consumer group oluÅŸturuldu: {group_name} @ {stream_name}")

        except redis.exceptions.ResponseError as e:
            if "BUSYGROUP" in str(e):
                print(f"â„¹ï¸  Consumer group zaten mevcut: {group_name}")
            else:
                print(f"âŒ Consumer group oluÅŸturma hatasÄ±: {e}")

    def consume_events(self, stream_name: str, group_name: str = None,
                      count: int = 10, block: int = 1000):
        """
        Event'leri consume et

        Args:
            stream_name: Stream adÄ±
            group_name: Consumer group (None = direct read)
            count: Okunacak event sayÄ±sÄ±
            block: Block sÃ¼resi (ms)
        """
        try:
            if group_name:
                # Consumer group ile okuma
                messages = self.redis_client.xreadgroup(
                    group_name,
                    self.consumer_id,
                    {stream_name: '>'},
                    count=count,
                    block=block
                )
            else:
                # Direct stream okuma
                messages = self.redis_client.xread(
                    {stream_name: '$'},
                    count=count,
                    block=block
                )

            # Messages iÅŸle
            for stream, events in messages:
                for event_id, fields in events:
                    self.process_event(stream.decode() if isinstance(stream, bytes) else stream,
                                     event_id, fields)

                    # Consumer group kullanÄ±yorsa ACK gÃ¶nder
                    if group_name:
                        self.redis_client.xack(stream_name, group_name, event_id)

            return len(messages)

        except Exception as e:
            print(f"âŒ Event consume hatasÄ±: {e}")
            return 0

    def process_event(self, stream_name: str, event_id: str, fields: Dict):
        """
        Event'i iÅŸle

        Args:
            stream_name: Stream adÄ±
            event_id: Event ID
            fields: Event field'larÄ±
        """
        try:
            # JSON field'larÄ± deserialize et
            processed_fields = {}
            for key, value in fields.items():
                try:
                    # JSON parse dene
                    processed_fields[key] = json.loads(value)
                except (json.JSONDecodeError, TypeError):
                    # Plain string olarak bÄ±rak
                    processed_fields[key] = value

            # Event type'a gÃ¶re iÅŸle
            event_type = processed_fields.get('event_type', 'unknown')

            if event_type == 'user_action':
                self._process_user_event(event_id, processed_fields)
            elif event_type == 'order_update':
                self._process_order_event(event_id, processed_fields)
            elif event_type == 'system_metric':
                self._process_metric_event(event_id, processed_fields)
            else:
                print(f"âš ï¸  Unknown event type: {event_type}")

        except Exception as e:
            print(f"âŒ Event processing hatasÄ±: {e}")

    def _process_user_event(self, event_id: str, fields: Dict):
        """
        User event'ini iÅŸle
        """
        user_id = fields.get('user_id', 'unknown')
        action = fields.get('action', 'unknown')

        print(f"ğŸ‘¤ User Event [{event_id[:10]}...]: {user_id} -> {action}")

        # Action'a gÃ¶re Ã¶zel iÅŸlemler
        if action == 'login':
            print(f"   ğŸ”“ User {user_id} logged in")
        elif action == 'purchase':
            amount = fields.get('amount', 0)
            print(f"   ğŸ’° User {user_id} made purchase: ${amount}")
        elif action == 'logout':
            duration = fields.get('session_duration', 0)
            print(f"   ğŸ‘‹ User {user_id} logged out (session: {duration}s)")

    def _process_order_event(self, event_id: str, fields: Dict):
        """
        Order event'ini iÅŸle
        """
        order_id = fields.get('order_id', 'unknown')
        status = fields.get('status', 'unknown')

        print(f"ğŸ“¦ Order Event [{event_id[:10]}...]: {order_id} -> {status}")

    def _process_metric_event(self, event_id: str, fields: Dict):
        """
        System metric event'ini iÅŸle
        """
        metric_name = fields.get('metric_name', 'unknown')
        value = fields.get('value', 0)

        print(f"ğŸ“Š Metric Event [{event_id[:10]}...]: {metric_name} = {value}")

    def start_consuming(self, stream_configs: List[Dict], group_name: str = None):
        """
        Continuous event consuming baÅŸlat

        Args:
            stream_configs: [{'stream': 'name', 'group': 'group'}, ...]
            group_name: Default group name
        """
        print(f"ğŸš€ Event consuming baÅŸlÄ±yor...")
        print(f"   Consumer ID: {self.consumer_id}")
        print(f"   Streams: {[config['stream'] for config in stream_configs]}")

        # Consumer group'larÄ± oluÅŸtur
        for config in stream_configs:
            stream_name = config['stream']
            consumer_group = config.get('group', group_name)

            if consumer_group:
                self.create_consumer_group(stream_name, consumer_group, '0')

        try:
            processed_count = 0

            while True:
                for config in stream_configs:
                    stream_name = config['stream']
                    consumer_group = config.get('group', group_name)

                    events_processed = self.consume_events(
                        stream_name,
                        consumer_group,
                        count=5,
                        block=1000
                    )

                    processed_count += events_processed

                if processed_count % 10 == 0 and processed_count > 0:
                    print(f"ğŸ“ˆ Processed {processed_count} events so far...")

        except KeyboardInterrupt:
            print(f"\nğŸ›‘ Consumer durduruldu: {processed_count} event iÅŸlendi")

class StreamAnalytics:
    """
    Stream analytics ve monitoring
    """

    def __init__(self, host='localhost', port=6379, db=0, password=None):
        """
        Stream analytics baÅŸlat
        """
        self.redis_client = redis.Redis(
            host=host,
            port=port,
            db=db,
            password=password,
            decode_responses=True
        )

    def get_stream_info(self, stream_name: str) -> Dict:
        """
        Stream bilgilerini al
        """
        try:
            info = self.redis_client.xinfo_stream(stream_name)

            return {
                'name': stream_name,
                'length': info['length'],
                'first_entry_id': info['first-entry'][0] if info['first-entry'] else None,
                'last_entry_id': info['last-entry'][0] if info['last-entry'] else None,
                'groups': info['groups']
            }

        except Exception as e:
            print(f"âŒ Stream info hatasÄ±: {e}")
            return {}

    def get_consumer_group_info(self, stream_name: str, group_name: str) -> Dict:
        """
        Consumer group bilgilerini al
        """
        try:
            groups = self.redis_client.xinfo_groups(stream_name)

            for group in groups:
                if group['name'] == group_name:
                    # Group consumers
                    consumers = self.redis_client.xinfo_consumers(stream_name, group_name)

                    return {
                        'name': group_name,
                        'pending': group['pending'],
                        'last_delivered_id': group['last-delivered-id'],
                        'consumers': [
                            {
                                'name': consumer['name'],
                                'pending': consumer['pending'],
                                'idle': consumer['idle']
                            }
                            for consumer in consumers
                        ]
                    }

            return {}

        except Exception as e:
            print(f"âŒ Consumer group info hatasÄ±: {e}")
            return {}

    def print_stream_dashboard(self, stream_names: List[str]):
        """
        Stream dashboard gÃ¶ster
        """
        print("ğŸ“Š Redis Streams Dashboard")
        print("=" * 60)

        for stream_name in stream_names:
            info = self.get_stream_info(stream_name)

            if not info:
                print(f"âŒ {stream_name}: Stream bulunamadÄ±")
                continue

            print(f"\nğŸŒŠ Stream: {stream_name}")
            print(f"   ğŸ“ Length: {info['length']} events")
            print(f"   ğŸ†” First ID: {info['first_entry_id']}")
            print(f"   ğŸ†” Last ID: {info['last_entry_id']}")
            print(f"   ğŸ‘¥ Groups: {info['groups']}")

            # Consumer groups detayÄ±
            try:
                groups = self.redis_client.xinfo_groups(stream_name)

                for group in groups:
                    group_info = self.get_consumer_group_info(stream_name, group['name'])

                    print(f"\n   ğŸ“‹ Group: {group['name']}")
                    print(f"      â³ Pending: {group_info['pending']}")
                    print(f"      ğŸ¯ Last delivered: {group_info['last_delivered_id']}")

                    for consumer in group_info['consumers']:
                        idle_minutes = consumer['idle'] // 60000  # ms to minutes
                        print(f"      ğŸ‘¤ {consumer['name']}: {consumer['pending']} pending, idle {idle_minutes}m")

            except Exception as e:
                print(f"      âš ï¸  Group info alÄ±namadÄ±: {e}")

    def analyze_event_patterns(self, stream_name: str, limit: int = 100):
        """
        Event pattern analizi
        """
        try:
            # Son event'leri al
            events = self.redis_client.xrevrange(stream_name, count=limit)

            if not events:
                print(f"ğŸ“Š {stream_name}: HenÃ¼z event yok")
                return

            # Pattern analizi
            event_types = {}
            user_actions = {}
            hourly_distribution = {}

            for event_id, fields in events:
                # Event type counting
                event_type = fields.get('event_type', 'unknown')
                event_types[event_type] = event_types.get(event_type, 0) + 1

                # User action counting
                if event_type == 'user_action':
                    action = fields.get('action', 'unknown')
                    user_actions[action] = user_actions.get(action, 0) + 1

                # Hourly distribution
                timestamp_ms = int(event_id.split('-')[0])
                hour = datetime.fromtimestamp(timestamp_ms / 1000).hour
                hourly_distribution[hour] = hourly_distribution.get(hour, 0) + 1

            # SonuÃ§larÄ± gÃ¶ster
            print(f"ğŸ“Š Event Pattern Analysis: {stream_name} (son {len(events)} event)")
            print("-" * 50)

            print("ğŸ“‹ Event Types:")
            for event_type, count in sorted(event_types.items(), key=lambda x: x[1], reverse=True):
                percentage = (count / len(events)) * 100
                print(f"   {event_type}: {count} ({percentage:.1f}%)")

            if user_actions:
                print("\nğŸ‘¤ User Actions:")
                for action, count in sorted(user_actions.items(), key=lambda x: x[1], reverse=True):
                    print(f"   {action}: {count}")

            print("\nğŸ• Hourly Distribution:")
            for hour in sorted(hourly_distribution.keys()):
                count = hourly_distribution[hour]
                bar = "â–ˆ" * (count // max(1, max(hourly_distribution.values()) // 20))
                print(f"   {hour:02d}:00 - {count:3d} {bar}")

        except Exception as e:
            print(f"âŒ Pattern analysis hatasÄ±: {e}")

def demo_redis_streams():
    """
    Redis Streams comprehensive demo
    """
    print("ğŸŒŠ Redis Streams Comprehensive Demo")
    print("=" * 50)

    # Producer oluÅŸtur
    producer = RedisStreamProducer()

    # Consumer oluÅŸtur
    consumer = RedisStreamConsumer()

    # Analytics oluÅŸtur
    analytics = StreamAnalytics()

    # 1. Sample events yayÄ±nla
    print("\n1ï¸âƒ£ Sample Events YayÄ±nlanÄ±yor:")

    # User events
    producer.publish_user_event('user_001', 'login', ip='192.168.1.100')
    producer.publish_user_event('user_001', 'page_view', page='/products')
    producer.publish_user_event('user_002', 'signup', email='user2@example.com')
    producer.publish_user_event('user_001', 'purchase', order_id='ord_123', amount=99.99)

    # Order events
    producer.publish_order_event('ord_123', 'confirmed', amount=99.99)
    producer.publish_order_event('ord_123', 'shipped', tracking='TRK123456')

    # System metrics
    producer.publish_system_metric('cpu_usage', 75.5, server='web01', datacenter='us-east')
    producer.publish_system_metric('memory_usage', 82.3, server='web01', datacenter='us-east')

    # 2. Stream info gÃ¶ster
    print("\n2ï¸âƒ£ Stream Dashboard:")
    analytics.print_stream_dashboard(['user_events', 'order_events', 'system_metrics'])

    # 3. Pattern analysis
    print("\n3ï¸âƒ£ Event Pattern Analysis:")
    analytics.analyze_event_patterns('user_events')

    # 4. Consumer group demo
    print("\n4ï¸âƒ£ Consumer Group Demo:")

    # Consumer group'larÄ± oluÅŸtur
    stream_configs = [
        {'stream': 'user_events', 'group': 'analytics_team'},
        {'stream': 'order_events', 'group': 'fulfillment_team'},
        {'stream': 'system_metrics', 'group': 'monitoring_team'}
    ]

    # Bir kaÃ§ event daha ekle
    print("   ğŸ“¡ Ek event'ler yayÄ±nlanÄ±yor...")
    for i in range(5):
        producer.publish_user_event(f'user_{i+10}', 'page_view', page=f'/page_{i}')
        time.sleep(0.1)

    # Consumer baÅŸlat (kÄ±sa sÃ¼re iÃ§in)
    print("   ğŸ‘‚ Consumer baÅŸlatÄ±lÄ±yor (5 saniye)...")

    import threading

    def consume_for_demo():
        """Demo iÃ§in kÄ±sa sÃ¼reli consuming"""
        end_time = time.time() + 5
        processed = 0

        while time.time() < end_time:
            for config in stream_configs:
                events = consumer.consume_events(
                    config['stream'],
                    config['group'],
                    count=2,
                    block=500
                )
                processed += events

        print(f"   âœ… Demo consumer: {processed} event iÅŸlendi")

    # Consumer thread baÅŸlat
    consumer_thread = threading.Thread(target=consume_for_demo)
    consumer_thread.start()
    consumer_thread.join()

    # 5. Final dashboard
    print("\n5ï¸âƒ£ Final Dashboard:")
    analytics.print_stream_dashboard(['user_events', 'order_events', 'system_metrics'])

    print("\nâœ… Redis Streams demo tamamlandÄ±!")
    print("ğŸ’¡ Production kullanÄ±mÄ± iÃ§in:")
    print("   - Stream retention policies ayarlayÄ±n")
    print("   - Consumer lag monitoring ekleyin")
    print("   - Error handling ve retry logic geliÅŸtirin")

if __name__ == "__main__":
    demo_redis_streams()
```

## ğŸ—ï¸ Stream Architecture Patterns

### 1. Event Sourcing

```python
class EventSourcingExample:
    """
    Event Sourcing pattern Redis Streams ile
    """

    def __init__(self, redis_client):
        self.redis = redis_client
        self.stream_name = "account_events"

    def create_account(self, account_id: str, initial_balance: float):
        """
        Hesap oluÅŸturma eventi
        """
        event = {
            'event_type': 'AccountCreated',
            'account_id': account_id,
            'initial_balance': initial_balance,
            'timestamp': datetime.now().isoformat()
        }

        return self.redis.xadd(self.stream_name, event)

    def deposit(self, account_id: str, amount: float):
        """
        Para yatÄ±rma eventi
        """
        event = {
            'event_type': 'MoneyDeposited',
            'account_id': account_id,
            'amount': amount,
            'timestamp': datetime.now().isoformat()
        }

        return self.redis.xadd(self.stream_name, event)

    def withdraw(self, account_id: str, amount: float):
        """
        Para Ã§ekme eventi
        """
        event = {
            'event_type': 'MoneyWithdrawn',
            'account_id': account_id,
            'amount': amount,
            'timestamp': datetime.now().isoformat()
        }

        return self.redis.xadd(self.stream_name, event)

    def get_account_balance(self, account_id: str) -> float:
        """
        Event'lerden hesap bakiyesini hesapla
        """
        events = self.redis.xrange(self.stream_name)
        balance = 0.0

        for event_id, fields in events:
            if fields.get('account_id') == account_id:
                event_type = fields.get('event_type')
                amount = float(fields.get('amount', 0))

                if event_type == 'AccountCreated':
                    balance = float(fields.get('initial_balance', 0))
                elif event_type == 'MoneyDeposited':
                    balance += amount
                elif event_type == 'MoneyWithdrawn':
                    balance -= amount

        return balance
```

### 2. CQRS (Command Query Responsibility Segregation)

```python
class CQRSPattern:
    """
    CQRS pattern Redis Streams ile
    """

    def __init__(self, redis_client):
        self.redis = redis_client
        self.command_stream = "commands"
        self.event_stream = "events"

    def send_command(self, command_type: str, payload: Dict):
        """
        Command gÃ¶nder
        """
        command = {
            'command_id': str(uuid.uuid4()),
            'command_type': command_type,
            'payload': json.dumps(payload),
            'timestamp': datetime.now().isoformat()
        }

        return self.redis.xadd(self.command_stream, command)

    def process_commands(self):
        """
        Command'larÄ± iÅŸle ve event Ã¼ret
        """
        commands = self.redis.xread({self.command_stream: '$'}, block=1000)

        for stream, events in commands:
            for event_id, fields in events:
                command_type = fields.get('command_type')
                payload = json.loads(fields.get('payload', '{}'))

                # Command'a gÃ¶re event Ã¼ret
                if command_type == 'CreateUser':
                    self._handle_create_user(payload)
                elif command_type == 'UpdateUser':
                    self._handle_update_user(payload)

    def _handle_create_user(self, payload: Dict):
        """
        CreateUser command'Ä±nÄ± iÅŸle
        """
        event = {
            'event_type': 'UserCreated',
            'user_id': payload['user_id'],
            'email': payload['email'],
            'timestamp': datetime.now().isoformat()
        }

        self.redis.xadd(self.event_stream, event)
```

## ğŸ§ª Hands-on Tasks

### Task 1: Real-time Analytics Pipeline

**Hedef**: E-ticaret event'leri iÃ§in real-time analytics

**Gereksinimler**:

- User behavior tracking
- Real-time metrics calculation
- Dashboard data aggregation
- Alerting for anomalies

### Task 2: Microservices Event Communication

**Hedef**: Microservices arasÄ± event-driven communication

**Gereksinimler**:

- Service-to-service messaging
- Event choreography pattern
- Saga pattern implementation
- Dead letter queue handling

### Task 3: Time-series Monitoring System

**Hedef**: System metrics collection ve analysis

**Gereksinimler**:

- Metric collection from multiple sources
- Time-based aggregations
- Retention policies
- Performance dashboards

## âœ… Checklist

Bu bÃ¶lÃ¼mÃ¼ tamamladÄ±ktan sonra:

- [ ] Redis Streams veri yapÄ±sÄ±nÄ± anlÄ±yorum
- [ ] Event producer/consumer implementasyonu yapabilirim
- [ ] Consumer groups kullanabiliyorum
- [ ] Event sourcing pattern uygulayabilirim
- [ ] CQRS pattern implementasyonu yapabilirim
- [ ] Stream analytics ve monitoring yapabilirim
- [ ] Production-ready stream architecture tasarlayabilirim
- [ ] Performance tuning ve scaling yapabilirim

## âš ï¸ Common Mistakes

### 1. Memory Management

**Problem**: Stream'ler sÄ±nÄ±rsÄ±z bÃ¼yÃ¼r
**Ã‡Ã¶zÃ¼m**: MAXLEN ve retention policies

### 2. Consumer Lag

**Problem**: Consumer'lar event'leri yetiÅŸemiyor
**Ã‡Ã¶zÃ¼m**: Horizontal scaling, processing optimization

### 3. Poison Messages

**Problem**: HatalÄ± event'ler processing'i durduruyor
**Ã‡Ã¶zÃ¼m**: Error handling, dead letter streams

## ğŸ”— Ä°lgili BÃ¶lÃ¼mler

- **Ã–nceki**: [Persistence ve Replication](04-persistence-replication.md)
- **Sonraki**: [Redis Clustering](06-clustering.md)
- **Ä°lgili**: [Kafka Streams](../01-kafka/04-streams.md)

---

**Sonraki AdÄ±m**: Redis'in cluster Ã¶zelliklerini Ã¶ÄŸrenmek iÃ§in [Redis Clustering](06-clustering.md) bÃ¶lÃ¼mÃ¼ne geÃ§in! ğŸš€
